{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.4,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True, memory_key=\"chat_history\", k=5\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"ë‹¹ì‹ ì€ ì˜í™” ì œëª©ì„ 3ê°œì˜ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” AIì…ë‹ˆë‹¤.\n",
    "            - ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ë°˜ë“œì‹œ 3ê°œì˜ ì´ëª¨ì§€ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "            - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë¬¼ì–´ë³´ëŠ” ê²½ìš°, chat_historyì—ì„œ ì°¸ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "            - ì²˜ìŒì˜ ë‘ ì˜ˆì‹œ(Top Gun, The Godfather)ëŠ” ì˜¤ì§ ë‹µë³€ í˜•ì‹ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë‹µë³€ì— ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
    "            \"\"\",\n",
    "        ),\n",
    "        fewshot_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=final_prompt, verbose=True, memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ë‹¹ì‹ ì€ ì˜í™” ì œëª©ì„ 3ê°œì˜ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” AIì…ë‹ˆë‹¤.\n",
      "            - ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ë°˜ë“œì‹œ 3ê°œì˜ ì´ëª¨ì§€ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë¬¼ì–´ë³´ëŠ” ê²½ìš°, chat_historyì—ì„œ ì°¸ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì²˜ìŒì˜ ë‘ ì˜ˆì‹œ(Top Gun, The Godfather)ëŠ” ì˜¤ì§ ë‹µë³€ í˜•ì‹ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë‹µë³€ì— ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
      "            \n",
      "Human: Top Gun\n",
      "AI: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "AI: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: íƒ€ì§œ\u001b[0m\n",
      "ğŸƒğŸ²ğŸ’°\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ğŸƒğŸ²ğŸ’°\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ë‹¹ì‹ ì€ ì˜í™” ì œëª©ì„ 3ê°œì˜ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” AIì…ë‹ˆë‹¤.\n",
      "            - ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ë°˜ë“œì‹œ 3ê°œì˜ ì´ëª¨ì§€ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë¬¼ì–´ë³´ëŠ” ê²½ìš°, chat_historyì—ì„œ ì°¸ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì²˜ìŒì˜ ë‘ ì˜ˆì‹œ(Top Gun, The Godfather)ëŠ” ì˜¤ì§ ë‹µë³€ í˜•ì‹ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë‹µë³€ì— ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
      "            \n",
      "Human: Top Gun\n",
      "AI: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "AI: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: íƒ€ì§œ\n",
      "AI: ğŸƒğŸ²ğŸ’°\n",
      "Human: ë‚˜ëŠ” ì „ì„¤ì´ë‹¤\u001b[0m\n",
      "ğŸ§Ÿâ€â™‚ï¸ğŸŒ†ğŸ¶\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ğŸ§Ÿâ€â™‚ï¸ğŸŒ†ğŸ¶\n"
     ]
    }
   ],
   "source": [
    "response1 = chain.invoke({\"input\": \"íƒ€ì§œ\"})\n",
    "print(response1[\"text\"])\n",
    "\n",
    "response2 = chain.invoke({\"input\": \"ë‚˜ëŠ” ì „ì„¤ì´ë‹¤\"})\n",
    "print(response2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ë‹¹ì‹ ì€ ì˜í™” ì œëª©ì„ 3ê°œì˜ ì´ëª¨ì§€ë¡œ ë³€í™˜í•˜ëŠ” AIì…ë‹ˆë‹¤.\n",
      "            - ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ë°˜ë“œì‹œ 3ê°œì˜ ì´ëª¨ì§€ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë¬¼ì–´ë³´ëŠ” ê²½ìš°, chat_historyì—ì„œ ì°¸ì¡°í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "            - ì²˜ìŒì˜ ë‘ ì˜ˆì‹œ(Top Gun, The Godfather)ëŠ” ì˜¤ì§ ë‹µë³€ í˜•ì‹ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë‹µë³€ì— ì‚¬ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
      "            \n",
      "Human: Top Gun\n",
      "AI: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "AI: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: íƒ€ì§œ\n",
      "AI: ğŸƒğŸ²ğŸ’°\n",
      "Human: ë‚˜ëŠ” ì „ì„¤ì´ë‹¤\n",
      "AI: ğŸ§Ÿâ€â™‚ï¸ğŸŒ†ğŸ¶\n",
      "Human: ì‚¬ìš©ìê°€ ì²« ë²ˆì§¸ë¡œ ë¬¼ì–´ë³¸ ì˜í™”ê°€ ë¬´ì—‡ì¸ê°€ìš”?\u001b[0m\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    }
   ],
   "source": [
    "memory_result = chain.invoke({\"input\": \"ì‚¬ìš©ìê°€ ì²« ë²ˆì§¸ë¡œ ë¬¼ì–´ë³¸ ì˜í™”ê°€ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
    "print(memory_result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='íƒ€ì§œ'),\n",
       "  AIMessage(content='ğŸƒğŸ²ğŸ’°'),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì „ì„¤ì´ë‹¤'),\n",
       "  AIMessage(content='ğŸ§Ÿ\\u200dâ™‚ï¸ğŸŒ†ğŸ¶'),\n",
       "  HumanMessage(content='ì‚¬ìš©ìê°€ ì²« ë²ˆì§¸ë¡œ ë¬¼ì–´ë³¸ ì˜í™”ê°€ ë¬´ì—‡ì¸ê°€ìš”?'),\n",
       "  AIMessage(content='ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
